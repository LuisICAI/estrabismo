{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "import os, shutil\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dir = \"/home/pabloperez/Repositorios/estrabismo/FotosDefinitivas/negative\"\n",
    "positive_dir = \"/home/pabloperez/Repositorios/estrabismo/FotosDefinitivas/positive\"\n",
    "train_dir = os.path.join(\"/home/pabloperez/Repositorios/estrabismo/FotosDefinitivas/train\")\n",
    "validation_dir = os.path.join(\"/home/pabloperez/Repositorios/estrabismo/FotosDefinitivas/validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_train_dir = os.path.join(train_dir, \"negative\")\n",
    "negative_validation_dir = os.path.join(validation_dir, \"negative\")\n",
    "positive_train_dir = os.path.join(train_dir, \"positive\")\n",
    "positive_validation_dir = os.path.join(validation_dir, \"positive\")\n",
    "\n",
    "os.makedirs(negative_train_dir, exist_ok=True)\n",
    "os.makedirs(negative_validation_dir, exist_ok=True)\n",
    "os.makedirs(positive_train_dir, exist_ok=True)\n",
    "os.makedirs(positive_validation_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Lista de nombres de archivo de las imágenes en los directorios \"negative\" y \"positive\"\n",
    "negative_files = [os.path.join(negative_dir, f) for f in os.listdir(negative_dir) if os.path.isfile(os.path.join(negative_dir, f))]\n",
    "positive_files = [os.path.join(positive_dir, f) for f in os.listdir(positive_dir) if os.path.isfile(os.path.join(positive_dir, f))]\n",
    "\n",
    "# Dividir la lista de nombres de archivo en conjuntos de entrenamiento y validación\n",
    "negative_train_files, negative_validation_files = train_test_split(negative_files, test_size=0.2)\n",
    "positive_train_files, positive_validation_files = train_test_split(positive_files, test_size=0.2)\n",
    "\n",
    "# Copiar imágenes de negative al directorio de entrenamiento\n",
    "for filename in negative_train_files:\n",
    "    destination = os.path.join(negative_train_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "# Copiar imágenes de negative al directorio de validación\n",
    "for filename in negative_validation_files:\n",
    "    destination = os.path.join(negative_validation_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "# Copiar imágenes de positive al directorio de entrenamiento\n",
    "for filename in positive_train_files:\n",
    "    destination = os.path.join(positive_train_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "# Copiar imágenes de positive al directorio de validación\n",
    "for filename in positive_validation_files:\n",
    "    destination = os.path.join(positive_validation_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "print(\"Número de imágenes de entrenamiento en negative: \", len(negative_train_files))\n",
    "print(\"Número de imágenes de validación en negative: \", len(negative_validation_files))\n",
    "print(\"Número de imágenes de entrenamiento en positive: \", len(positive_train_files))\n",
    "print(\"Número de imágenes de validación en positive: \", len(positive_validation_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(300, 300, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5)) # Es para evitar overfitting\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now()\n",
    "print(f'Hora de inicio de celda: {n}')\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=10, #100\n",
    "      epochs=20, #100\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=10) #50\n",
    "\n",
    "nf = datetime.datetime.now()\n",
    "print(f'Hora de final de celda: {nf}')\n",
    "print(f'Tiempo total: {nf-n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Modelos/Version1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbd31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
