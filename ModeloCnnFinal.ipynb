{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 16:53:36.274164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 16:53:36.349669: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-04 16:53:36.369944: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-04 16:53:36.805846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/pabloperez/anaconda3/envs/mbd31/lib/\n",
      "2023-04-04 16:53:36.805888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/pabloperez/anaconda3/envs/mbd31/lib/\n",
      "2023-04-04 16:53:36.805892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "import os, shutil\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dir = \"/home/pabloperez/Repositorios/estrabismo/photos/negative\"\n",
    "positive_dir = \"/home/pabloperez/Repositorios/estrabismo/photos/positive\"\n",
    "train_dir = os.path.join(\"/home/pabloperez/Repositorios/estrabismo/ModelSample/train\")\n",
    "validation_dir = os.path.join(\"/home/pabloperez/Repositorios/estrabismo/ModelSample/validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "negative_train_dir = os.path.join(train_dir, \"negative\")\n",
    "negative_validation_dir = os.path.join(validation_dir, \"negative\")\n",
    "positive_train_dir = os.path.join(train_dir, \"positive\")\n",
    "positive_validation_dir = os.path.join(validation_dir, \"positive\")\n",
    "\n",
    "os.makedirs(negative_train_dir, exist_ok=True)\n",
    "os.makedirs(negative_validation_dir, exist_ok=True)\n",
    "os.makedirs(positive_train_dir, exist_ok=True)\n",
    "os.makedirs(positive_validation_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Lista de nombres de archivo de las imágenes en los directorios \"negative\" y \"positive\"\n",
    "negative_files = [os.path.join(negative_dir, f) for f in os.listdir(negative_dir) if os.path.isfile(os.path.join(negative_dir, f))]\n",
    "positive_files = [os.path.join(positive_dir, f) for f in os.listdir(positive_dir) if os.path.isfile(os.path.join(positive_dir, f))]\n",
    "\n",
    "# Dividir la lista de nombres de archivo en conjuntos de entrenamiento y validación\n",
    "negative_train_files, negative_validation_files = train_test_split(negative_files, test_size=0.2)\n",
    "positive_train_files, positive_validation_files = train_test_split(positive_files, test_size=0.2)\n",
    "\n",
    "# Copiar imágenes de negative al directorio de entrenamiento\n",
    "for filename in negative_train_files:\n",
    "    destination = os.path.join(negative_train_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "# Copiar imágenes de negative al directorio de validación\n",
    "for filename in negative_validation_files:\n",
    "    destination = os.path.join(negative_validation_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "# Copiar imágenes de positive al directorio de entrenamiento\n",
    "for filename in positive_train_files:\n",
    "    destination = os.path.join(positive_train_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "# Copiar imágenes de positive al directorio de validación\n",
    "for filename in positive_validation_files:\n",
    "    destination = os.path.join(positive_validation_dir, os.path.basename(filename))\n",
    "    shutil.copy(filename, destination)\n",
    "\n",
    "print(\"Número de imágenes de entrenamiento en negative: \", len(negative_train_files))\n",
    "print(\"Número de imágenes de validación en negative: \", len(negative_validation_files))\n",
    "print(\"Número de imágenes de entrenamiento en positive: \", len(positive_train_files))\n",
    "print(\"Número de imágenes de validación en positive: \", len(positive_validation_files))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 16:53:44.306198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.309783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.309880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.310392: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 16:53:44.310899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.310993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.311072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.626799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.626976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.627062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-04 16:53:44.627130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5678 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(300, 300, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dropout(0.5)) # Es para evitar overfitting\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hora de inicio de celda: 2023-04-04 16:53:48.934333\n",
      "Found 223 images belonging to 2 classes.\n",
      "Found 57 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 16:53:50.411937: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-04-04 16:53:51.651192: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 402ms/step - loss: 0.4926 - acc: 0.8655\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 2s 281ms/step - loss: 0.4201 - acc: 0.8655\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 2s 280ms/step - loss: 0.4054 - acc: 0.8655\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 2s 283ms/step - loss: 0.4100 - acc: 0.8655\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 2s 280ms/step - loss: 0.3456 - acc: 0.8655\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 2s 276ms/step - loss: 0.3089 - acc: 0.8700\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 2s 279ms/step - loss: 0.2552 - acc: 0.8924\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 2s 279ms/step - loss: 0.2319 - acc: 0.9058\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 2s 280ms/step - loss: 0.2375 - acc: 0.9238\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 2s 281ms/step - loss: 0.1675 - acc: 0.9596\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 2s 277ms/step - loss: 0.1617 - acc: 0.9552\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 2s 276ms/step - loss: 0.1985 - acc: 0.9327\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 2s 276ms/step - loss: 0.1460 - acc: 0.9507\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 2s 277ms/step - loss: 0.1270 - acc: 0.9507\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 2s 275ms/step - loss: 0.1473 - acc: 0.9507\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 2s 273ms/step - loss: 0.1058 - acc: 0.9731\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 2s 273ms/step - loss: 0.1354 - acc: 0.9507\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 2s 275ms/step - loss: 0.0960 - acc: 0.9686\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 2s 277ms/step - loss: 0.0781 - acc: 0.9776\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 2s 274ms/step - loss: 0.0533 - acc: 0.9865\n",
      "Hora de final de celda: 2023-04-04 16:54:33.606370\n",
      "Tiempo total: 0:00:44.672037\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "n = datetime.datetime.now()\n",
    "print(f'Hora de inicio de celda: {n}')\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator, #100\n",
    "      epochs=20) #50\n",
    "\n",
    "nf = datetime.datetime.now()\n",
    "print(f'Hora de final de celda: {nf}')\n",
    "print(f'Tiempo total: {nf-n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Modelos/Version1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m val_acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mval_acc\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      3\u001b[0m loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m val_loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbd31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
